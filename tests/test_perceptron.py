"""
Fichier : test_perceptron.py
Description : Tests unitaires pour la classe Perceptron (version learning_rate / max_iter)
Auteur : Projet Perceptron
"""

import numpy as np
import pytest
import logging
from perceptron import Perceptron
from sklearn.datasets import make_classification

# Configuration du logger
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# ==========================================================================================
# üîπ TEST 1 : Initialisation
# ==========================================================================================
def test_initialisation():
    logger.info("Test: Initialisation du perceptron")
    p = Perceptron(learning_rate=0.1, max_iter=100)
    assert isinstance(p.learning_rate, float)
    assert isinstance(p.max_iter, int)
    assert p.weights is None
    assert p.bias is None

# ==========================================================================================
# üîπ TEST 2 : Apprentissage sur donn√©es lin√©airement s√©parables (fonction AND)
# ==========================================================================================
def test_predict_linearly_separable():
    logger.info("Test: Fonction AND logique (lin√©airement s√©parable)")
    X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y = np.array([0, 0, 0, 1])  # sortie 0/1 pour la logique AND
    p = Perceptron(learning_rate=0.1, max_iter=20)
    p.fit(X, y)
    preds = p.predict(X)
    assert (preds == y).all(), f"Pr√©dictions incorrectes : {preds} != {y}"

# ==========================================================================================
# üîπ TEST 3 : Effet du learning rate
# ==========================================================================================
def test_learning_rate_effect():
    logger.info("Test: Effet du learning rate")
    X = np.array([[0], [1]])
    y = np.array([0, 1])

    p1 = Perceptron(learning_rate=0.01, max_iter=10)
    p2 = Perceptron(learning_rate=1.0, max_iter=10)

    p1.fit(X, y)
    p2.fit(X, y)

    assert not np.allclose(p1.weights, p2.weights), "Les poids devraient √™tre diff√©rents selon le learning rate."

# ==========================================================================================
# üîπ TEST 4 : Performance sur un dataset g√©n√©r√© avec sklearn
# ==========================================================================================
def test_classification_accuracy():
    logger.info("Test: Dataset sklearn (√©valuation de la pr√©cision)")
    X, y = make_classification(
        n_samples=100, n_features=2, n_classes=2,
        n_informative=2, n_redundant=0, random_state=42
    )
    p = Perceptron(learning_rate=0.1, max_iter=100)
    p.fit(X, y)
    preds = p.predict(X)
    accuracy = np.mean(preds == y)
    logger.info(f"Pr√©cision du mod√®le : {accuracy:.2f}")
    assert accuracy > 0.7, f"Pr√©cision trop faible : {accuracy:.2f}"

# ==========================================================================================
# üîπ TEST 5 : Gestion d‚Äôentr√©es invalides
# ==========================================================================================
def test_invalid_inputs():
    logger.info("Test: Donn√©es invalides")
    p = Perceptron(learning_rate=0.1, max_iter=10)
    with pytest.raises(ValueError):
        p.fit(np.array([]), np.array([]))

# ==========================================================================================
# üîπ TEST 6 : Cas non s√©parable (XOR)
# ==========================================================================================
def test_non_separable_data():
    logger.info("Test: Cas XOR non s√©parable")
    X = np.array([[0,0], [0,1], [1,0], [1,1]])
    y = np.array([0, 1, 1, 0])  # XOR
    p = Perceptron(learning_rate=0.1, max_iter=100)
    p.fit(X, y)
    preds = p.predict(X)
    acc = np.mean(preds == y)
    logger.info(f"Pr√©cision sur XOR : {acc:.2f}")
    assert acc < 1.0, "Le perceptron ne devrait pas r√©soudre parfaitement XOR."
